## Summary

Nice work! In this lesson you’ve learned a broad overview of the different aspects of the Hugging Face transformers package. Specifically, you’ve learned how to:

use pipeline() to perform model inference perform tokenization and preprocessing to prep model inputs
find and interpret model cards
choose transformer models for different language tasks
use an encoder-only model like BERT for sentiment analysis
use an encoder-decoder model like T5 for summarization
use a decoder-only model like GPT-2 for text
implement different token selection and search strategies for text generation using transformers

Preview: Docs Generative AI can create blogs, write ad copy, create new content based on text input, and is capable of summarizing and changing the style and tone of text content.
generation implement different token selection and search strategies for text generation using transformers
You’re now set to explore more transformer models on your own!